Pre-trained model,bias type,value
BERT-Base,ans-len,12.51
BERT-Base,word-dist,8.62
BERT-Base,cos-sim,2.63
BERT-Base,sim-ents,2.48
BERT-Base,sim-word,1.04
BERT-Base,subj-pos,1.01
BERT-Base,ans-pos,0
BERT-Base,average,4.041429
RoBERTa-Base,ans-len,11.55
RoBERTa-Base,word-dist,6.55
RoBERTa-Base,cos-sim,2.30
RoBERTa-Base,sim-ents,3.25
RoBERTa-Base,sim-word,0.68
RoBERTa-Base,subj-pos,0
RoBERTa-Base,ans-pos,0
RoBERTa-Base,average,3.475714
Electra-Base,ans-len,10.31
Electra-Base,word-dist,8.05
Electra-Base,cos-sim,2.17
Electra-Base,sim-ents,2.74
Electra-Base,sim-word,0.12
Electra-Base,subj-pos,0.31
Electra-Base,ans-pos,0
Electra-Base,average,3.385714
RoBERTa-Large,ans-len,10.87
RoBERTa-Large,word-dist,4.81
RoBERTa-Large,cos-sim,2.43
RoBERTa-Large,sim-ents,0.87
RoBERTa-Large,sim-word,0.37
RoBERTa-Large,ans-pos,0
RoBERTa-Large,subj-pos,0
RoBERTa-Large,average,2.764286